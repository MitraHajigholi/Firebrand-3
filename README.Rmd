---
title: "Applied Data Science"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Packages
Packages we'll look at today:

- odbc / readxl / readr / dbplyr for data access
- tidyverse for data manipulation
- DataExplorer for providing of our data
- modelr / rsamples for sampling strategy
- recipes for performing feature engineering
- glmnet / glmnetUtils / h2o / FFTrees for building models
- yardstick / broom for evaluation
- rmarkdown for documentation

## Working with databases
We need a database connection before we can do anything with our database
```{r}
library(DBI)  # talk with databases, a driver
library(odbc) # allows us to talk with DBI drivers

driver = "SQL server" # prgram that allows us to talk with the database
server = "fbmcsads.database.windows.net"
database = "WideWorldImporters-Standard"
uid = "adatumadmin"
pwd = "Pa55w.rdPa55w.rd"


con <- dbConnect(odbc(),
                 driver = driver,
                 server = server,
                 database = database,
                 uid = uid,
                 pwd = pwd)
```

Now that we have a DB connection, we can write SQL in a code chunk.
```{sql connection=con}
select top 5 * from flights

```


We can use dbplyr to construct dplyr commands that work on the DB.

```{r}
library(dbplyr) # translates into sql 
library(tidyverse) # group_by and filter and stuff in this package
flights_tbl <- tbl(con, "flights")  # talk with database con and flights table

flights_tbl %>% 
  filter(month<=6) %>%  
  group_by(origin) %>% 
  summarise(n = n(), # n is number of rows
            mean_dist = mean(distance)) %>% 
  show_query()

```

We can also work with tables that aren't in the default schema.
```{r}
purchaseorders_tbl <-tbl(con, in_schema("purchasing", "purchaseorders")) # selects purchaseorders in purchasing 

purchaseorders_tbl %>%  
  top_n(5)
```

We can use the 'Id()' function from DBI to work with schema more generically within a database. This means we aren't restricted to just SELECT statements.

```{r error = TRUE} 
# error = true, we will se the error code it generated
dbGetQuery(con,"CREATE SCHEMA DBIexample5")  # insert a number for your examlpe
dbWriteTable(con,"iris", iris, overwrite = TRUE)
#Read from newly written table
head(dbReadTable(con,"iris"))
#Read from a table in a schema
head(dbReadTable(con, Id(schema="20774A", table = "CustomerTransactions")))
#If a write methid is supportewd by the driver, this will work
dbWriteTable(con, Id(schema="DBIexampleMitra", table = "iris", iris, overwrite = TRUE))
```

Some of our code could fail in that section so we used 'error=TRUE' to be able to carry on even if some of the code errored. Great for optional code or things with bad connections.


## Exploratory

```{r eval = FALSE}
## eval = FALSE, should evaluate this chunk of code or not, when I nit it.
flights_tbl %>% 
  as_data_frame() %>% 
  DataExplorer::GenerateReport()

```


Questions arising frmo the basic report:

1. Why is there a day with double the number of flights?
2. We need to address the high correlation between time columns
3. Why is there negative correlation between 'flight' and 'distance'?
4. Do we need to do anything about missings or can we just remove the rows
5. look up why there is a peak in middle of the month?

Things to imlpement later in the workflow due to the EDA (explorer tree data analysis):

1. We need to address the high correlation beteen time columns
2. We need to group low freq airlines carries
3. Bivariate for anlyzing two things in realtion to each other

### Answering our questions

> Why is there a day with double the number of flights?

Are there dublicate rows?

```{r}
flights_tbl %>% 
  filter(day == 15) %>% 
  distinct()  %>%  
  summarise(n())  %>%  # count the data
  as_data_frame() ->  # force it to give it the content and not sql code
  distict_count  # create a uniqe list of using distict count
  
  # get all rows if dublicate or not
flights_tbl %>% 
  filter(day == 15) %>% 
  summarise(n())  %>%  
  as_data_frame() ->
  row_count 

# if the sructure and values are the same return true,
identical(row_count, distict_count) #one row per observed flight?

```

But are the number of rows unusual?

```{r}
library(ggplot2)
flights_tbl %>% 
  group_by(day) %>% 
  summarise(n = n(), n_distinct(flight)) %>% 
  arrange(day)

## to plot the data instead : 
flights_tbl %>% 
  group_by(day) %>% 
  summarise(n = n(), n_distinct(flight)) %>%
  as_data_frame() %>% 
  ggplot(aes(day,y = n)) + geom_col()  # does not do any binning of the data

```
Data is fine, the problem is in our visualization. Doing histogram, split continus numbers have to group them two in a day. the spike looks to be a problem but its not.

Looks like the jump in the histogram is an artifact of binning the data. s'oh!


### Bivariate analysis
```{r}

flights_tbl %>% 
  select_if(is.numeric) %>% 
  as_data_frame() %>%   # need to convert to a data frame from sql data
  gather(col,val,-dep_delay) %>% # dont pivot the dep_delay column, gather and pivot creates the variables col and val
  filter(col!= "arr_delay", dep_delay < 500) %>%  # filter out arr_delay to see better result
  ggplot(aes(x=val, y=dep_delay)) + 
  #geom_point() +  # this takes long time since its plotting row by row
  geom_bin2d() +
  facet_wrap(~col, scales = "free") + # takes different parts of our data to produce them as charts
  scale_fill_gradientn(colours= viridisLite::viridis(256, option = "D"))

```






